---
title: "Exercises of Chapter 6: Non-uniformly Distributed Random Number Generation"
author: "Qihun Yang"
date: "2023-03-12"
output: html_document
---

## Ex.1
$n$ 个如下离散型分布随机数: $P(X=1)=1 / 3, P(X=2)=2 / 3$.

(1)生成 $n=100$ 个这样的随机数，计算 $X$ 取1的百分比;\
(2)生成 $n=1000$ 个这样的随机数，计算 $X$ 取1的百分比;\
(3)生成 $n=10000$ 个这样的随机数，计算 $X$ 取1的百分比;

```{r setup, include=T}
rm(list = ls())
set.seed(1)
fun1=function(i){
  u=runif (1,0,1)
  return(ifelse(u<1/3,1,2))
}
T_2 = list()
p = rep(0,3)
for (j in 1:3) {
  T_2[[j]] = sapply(1:10^(j+1), FUN=fun1)
  p[j] = (sum(T_2[[j]] == 1))/length(T_2[[j]])
  print(p[j])
}
```

(4)$E X=5 / 3 \quad D X=2 / 9$ 由中心极限定理得 $\frac{\bar{X}-\frac{5}{3}}{\sqrt{\frac{2}{9 n}}} \rightarrow N(0,1)$ 由 $f_n=2-\bar{X}$ 得 $f_n$ 的渐近分布 : $f_n \rightarrow N\left(\frac{1}{3}, \frac{2}{9 n}\right)$ 对 $H_0: P(X=1)=1 / 3 ; \quad H_1: P(X=1) \neq 1 / 3$ 进行检验: 检验统计量 $Z_n=\frac{f_n-\frac{1}{3}}{\sqrt{\frac{2}{9 n}}}$ 在 $H_0$ 下近似服从 $N(0,1)$ $\alpha=0.05$ 下, 当 $\left|Z_n\right|>Z_{0.975}=1.9599$ 时拒绝 $H_0$ 。

```{r}
print(paste('n=100时计算检验统计量为',round(abs((p[1]-1/3)/sqrt(2/9/100)),4),sep = ''))
print(paste('n=1000时计算检验统计量为',round(abs((p[2]-1/3)/sqrt(2/9/1000)),4),sep = ''))
print(paste('n=10000时计算检验统计量为',round(abs((p[3]-1/3)/sqrt(2/9/10000)),4),sep = ''))
```

在$\alpha=0.05$ 下，都得到不拒绝$H_0$的结论。

## Ex.3
洗好一副编号为 $1,2, \ldots, 54$ 的纸牌，依次抽出来，若第次抽取到编号为 $i$ 的纸牌则为成功抽取。编写程序估计成功抽 取个数 $T$ 的期望和方差，推导理论公式并与模拟结果进行比较。\
    (1)理论推导:\
    (a)先求: 共有 $N$ 张牌，洗牌后依次抽取完毕，至少有 1 次成功抽取的概率。 记 $A_i=$ {第 $i$ 次抽取是成功抽取 $\}$, 则有 $$
    P\left(A_i\right)=\frac{1}{N}, \quad P\left(A_i A_j\right)=\frac{1}{N(N-1)}, \quad \cdots, \quad P\left(A_1 \cdots A_N\right)=\frac{1}{N !} .
    $$ 故至少有 1 次成功抽取的概率为: $$
    \begin{aligned}
    P\left(A_1 \cup A_2 \cdots \cup A_N\right) & =\sum_{i=1}^N P\left(A_i\right)-\sum_{1 \leq i<j \leq N} P\left(A_i A_j\right)+\cdots+(-1)^{N-1} \cdot P\left(A_1 \cdots A_N\right) \\
    & =\left(\begin{array}{c}
    N \\
    1
    \end{array}\right) \frac{1}{N}-\left(\begin{array}{c}
    N \\
    2
    \end{array}\right) \frac{1}{N(N-1)}+\cdots+(-1)^{N-1} \cdot\left(\begin{array}{l}
    N \\
    N
    \end{array}\right) \frac{1}{N !} \\
    & =\sum_{k=1}^N(-1)^{k-1} \frac{1}{k !}
    \end{aligned}
    $$ (b)下面求 $P(T=k)$ 设共有 $N$ 张牌，则有 $k$ 次成功抽取的可能情形共有 $\left(\begin{array}{c}N \\ k\end{array}\right)$ 种。 指定的 $k$ 次成功抽取的概率为 $$
    \frac{1}{N(N-1) \cdots(N-k+1)}=\frac{(N-k) !}{N !}
    $$ 由(a),剩余的 $N-k$ 次都没有成功抽取的概率为 $$
    1-\sum_{i=1}^{N-k}(-1)^{i-1} \frac{1}{i !}=1+\sum_{i=1}^{N-k}(-1)^i \frac{1}{i !}=\sum_{i=0}^{N-k} \frac{(-1)^i}{i !} .
    $$ 故 $N=54$ 时，成功抽取个数为 $k$ 的概率为 $$
    \begin{aligned}
    P(T=k) & =\left(\begin{array}{l}
    N \\
    k
    \end{array}\right) \cdot \frac{(N-k) !}{N !} \cdot \sum_{i=0}^{N-k} \frac{(-1)^i}{i !} \\
    & =\frac{1}{k !} \sum_{i=1}^{N-k} \frac{(-1)^i}{i !} \\
    & =\frac{1}{k !} \sum_{i=1}^{54-k} \frac{(-1)^i}{i !}
    \end{aligned}
    $$ (c)下面求 $E(T)$ $$
    E(T)=\sum_{k=0}^{54} k \cdot \frac{1}{k !} \sum_{i=0}^{54-k} \frac{(-1)^i}{i !} .=1
    $$ (d)下面求 $\operatorname{Var}(T)$ $$
    \operatorname{Var}(T)=E\left(T^2\right)-(E(T))^2=\sum_{k=0}^{54} k^2 \cdot \frac{1}{k !} \sum_{i=0}^{54-k} \frac{(-1)^i}{i !}-1^2=1 .
    $$ 
    (2)随机试验验证
```{r cards}
m <- 54
n <- 10000
T <- c()
x0 <- 1:m

for (i in 1:n)
{
  set.seed(i)
  x <- sample(x0) # Shuffle the cards
  T[i] = sum(x-x0==0)
}
mean(T)
var(T)
```

## Ex.4
```{r dice}
n <- 1000
T <- c()
start <- 2
end <- 12


for (i in 1:n) {
  index <- data.frame(start:end,c(rep(TRUE,end-start+1)))
  num <- 0
  set.seed(i)
  while (as.logical(sum(index[,2])) == TRUE)
  {
    x1 <- ceiling(6*runif(1, min = 0, max = 1))
    x2 <- ceiling(6*runif(1, min = 0, max = 1))
    temp <- x1+x2
    if (index[index[,1]==temp,2])
      index[index[,1]==temp,2] = FALSE
    num = num +1
  }
  T[i] = num
}
mean(T)
var(T)
```

## Ex.9

Directly sample from $\exp(1)$ distribution and keep those less than $0.05$ until obtaining $1000$ random numbers.
```{r 15.1}
set.seed(1)
n = 1000
count = 0
X <- c()
while (count < n){
  r <- -log(runif(1,0,1))
  if (r < 0.05){
    count = count+1
    X[count] <- r 
  }
}
```
Expectation:
```{r 15.2}
mean(X)
```
The following theoretical derivation:
\begin{aligned}
E(X|X<0.05)&=\int_{0}^{0.05}\frac{xe^{-x}}{1-e^{-0.05}}dx \\
&=\frac{-1}{1-e^{-0.05}}\int_{0}^{0.05}xde^{-x} \\
&=\frac{-1}{1-e^{-0.05}}(xe^{-x}|_0^{0.05}-\int_{0}^{0.05}e^{-x})dx \\
&=\frac{-1}{1-e^{-0.05}}(0.05e^{-0.05}+e^{-0.05}-1)
\end{aligned}
theoretical variance:
```{r 15.3}
(0.05*exp(-0.05)+exp(-0.05)-1)/(exp(-0.05)-1)
```
Two expectations are approximately equal.

## Ex.12
Method 1: Inverse CDF:\
I first generate $U_1 \sim U(0,1), \quad U_2 \sim U(0,1)$. 
$Y_1:=-\ln U_1 \sim \operatorname{Exp}(1), \quad Y_2:=-\ln U_2 \sim \operatorname{Exp}(1)$,
therefore $X=Y_1+Y_2=-\ln U_1 U_2 \sim G a m m a(2,1)$  


Method 2: Rejection Sampling\
I adopt the rejection sampling in this problem, where the key process lies in the selection of envelope $g(x)$. I evaluate the efficiency of the method by examine the execution time.

( 1 )

$g(x)=\frac{1}{2}e^{-\frac{1}{2}x},\ x>0$

$$h(x)=\frac{p(x)}{g(x)}=2xe^{-\frac{1}{2}x}$$
$$h^{\prime}(x)=(2-x)e^{-\frac{1}{2}x}$$
To maximize $h(x)$, let $c=\max{h(x)}=h(2)=4/e$. 
The final expression of $h(x)$ is:
$$h(x)=\frac{p(x)}{g(x)}=\frac{x}{2}e^{-\frac{1}{2}x+1}$$

Therefore, we can obtain the random number according to the following algorithm.
```{r 20.1}
set.seed(1)
n = 1000
count = 0
X <- c()
s=Sys.time()
while (count < n){
  while (TRUE) {
    r <- -0.5*log(runif(1,0,1))
    Y <- runif(1,0,1)
    if (Y > (r/2)*exp(-0.5*r+1)){
      next
    }
    else{
      count = count+1
      X[count] <- r
      break
    }
  }
}
e=Sys.time()
#operation time
print(e-s)
```

( 2 )

$g(x)=\frac{1}{8}e^{-\frac{1}{8}x},\ x>0$

$$h(x)=\frac{p(x)}{g(x)}=8xe^{-\frac{7}{8}x}$$
$$h^{\prime}(x)=(8-7x)e^{-\frac{1}{2}x}$$
To maximize $h(x)$, let $c=\max{h(x)}=h(8/7)=64/7e$
The final expression of $h(x)$ is:
$$h(x)=\frac{p(x)}{g(x)}=\frac{7x}{8}e^{-\frac{7}{8}x+1}$$
```{r 20.2}
set.seed(1)
n = 1000
count = 0
X <- c()
s=Sys.time()
while (count < n){
  while (TRUE) {
    r <- -0.5*log(runif(1,0,1))
    Y <- runif(1,0,1)
    if (Y > (7*r/8)*exp(-0.875*r+1)){
      next
    }
    else{
      count = count+1
      X[count] <- r
      break
    }
  }
}
e=Sys.time()
#operation time
print(e-s)
```

It can be seen that the second algorithm takes about half the time of the first algorithm, so the second algorithm is more efficient. 

## Ex.15


( 1 ) Inverse cdf method

the Cumulative Distribution Function is 
$$
F(x)=
\left\{
\begin{array}{lr}\frac{1}{2}e^x,& x<0\\
1-\frac{1}{2}e^{-x},& x\geq 0
\end{array}
\right.
$$
Inverse Function:
$$
F^{-1}(y)=
\left\{
\begin{array}{lr}\ln2y,& x<0\\
-\ln(2-2y),& x\geq 0
\end{array}
\right.
$$
Algorithm:
```{r 23.1}
r <- runif(1,0,1)
if (r < 0.5){
   X <- log(2*r)
} else {
  X <- -log(2-2*r)
}
X
```

( 2 ) Mixture Sampling

The pdf can be represented as:
$$
p(x)=\frac{1}{2}e^xI\{x<0\}+\frac{1}{2}e^{-x}I\{x\geq0\}
$$
that is, $P\{I=1\}=P\{I=2\}=\frac{1}{2}$,
from which we obtain the algorithm:
```{r 23.2}
u1 <- runif(1,0,1)
if (u1 < 0.5){
  u2 <- runif(1,0,1)
  X <- log(u2)
} else {
  u2 <- runif(1,0,1)
  X <- -log(u2)
}
X
```

